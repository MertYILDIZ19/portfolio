<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" type="text/css" href="styles.css">
  <style>
    body {
      display: flex;
      flex-direction: column;
      min-height: 100vh;
      margin: 0;
      background-image: url('background.jpg');
      background-size: cover;
      background-position: center;
    }

    #content {
      flex: 1;
    }

    footer {
      padding: 20px;
      text-align: center;
      margin-top: auto; /* Pushes the footer to the bottom */
    }

    header {
      display: flex;
      align-items: center;
      justify-content:space-between; /* Aligns the sections to the right */
      padding: 30px 300px; /* Adds padding to the header */
    }

    header img {
      width: 100px; /* Adjust the size of the profile picture */
      height: 100px;
      border-radius: 50%; /* Apply circular border */
      margin-right: 50px; /* Add some spacing between the image and the name */
    }

    header .profile-info {
      display: flex;
      align-items: center;
    }

    header h1 {
      margin: 0;
    }

  </style>
</head>
<body>
  <header>
    <div class="profile-info">
      <img src="profile_pic.jpg" alt="Profile Picture">
      <h1>Mert YILDIZ</h1>
    </div>
    
    <nav>
      <ul>
        <li><a href="main.html">Home</a></li>
        <li><a href="education.html">Education</a></li>
        <li><a href="work.html">Work Experience</a></li>
        <li><a href="projects.html">Projects</a></li>
        <li><a href="honor_awards.html">Honor & Awards</a></li>
      </ul>
    </nav>
  </header>

  <section id="projects" style="color: white;">
    <h2>Projects</h2>
    <div class="project">
      <h3>Continual-Learning</h3>
      <p>
        Academics and practitioners alike believe that continual learning (CL) is a fundamental step towards artificial intelligence. Continual learning is the ability of a model to learn continually from a stream of data. In practice, this means supporting the ability of a model to autonomously learn and adapt in production as new data comes in. Some may know it as auto-adaptive learning, or continual AutoML. The idea of CL is to mimic humans ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan.
      </p>
      <p>
        In this repository you can see the notebook that I have applied Continual Learning on colorectal cancer histology data. I have used simple 3 layers CNN to train the model. I have started by showing the importance of regularization against over-fitting. Then I have trained the model without continual learning for 4 tasks and compared the accuracy with the model that has been trained with Elastic Weight Consolidation (EWC).
      </p>
      <p>
        You can check the project in details and the code 
        <a href="https://github.com/MertYILDIZ19/Continual-Learning" target="_blank">
          here</a>.
      </p>
    </div>

    <div class="project">
      <h3>Named-Entity-Recognition</h3>
      <p>
        Named Entity Recognition (NER) is a natural language processing technique that identifies and categorizes named entities in text, such as names of people, organizations, locations, and more. It plays a crucial role in various applications like information retrieval, text analysis, and automated decision-making. NER models are trained using annotated datasets to accurately recognize and label named entities, enabling machines to understand the context and extract key information from text.
      </p>
      <p>
        I have done a project that focused on Named Entity Recognition (NER) and employed various LSTM-based models for sequence tagging. The models were trained to categorize entities into predefined categories such as Person, Location, and Corporation. By using Bidirectional LSTM (BiLSTM) models and incorporating a CRF layer, the project achieved improved performance compared to baseline LSTM models. The experiments involved tuning parameters such as the number of layers, dropout rates, and pretrained embeddings. Overall, the project demonstrated the effectiveness of BiLSTM-CRF in accurately identifying and categorizing entities in text.
      </p>
      <p>
        You can check the project in details and the code 
        <a href="https://github.com/MertYILDIZ19/Named-Entity-Recognition" target="_blank">
          here</a>.
      </p>
    </div>

    <div class="project">
      <h3>Text(Docs) Classification</h3>
      <p>
        I have done a project that I have implemented different models with CountVectorizer and TfidfTransformers simply but it did not return good results to classify the documents. Therefore I have decided to train the model with XgBoost and CatBoost with pretrained Glove Embeddings. After training with both for different size of dimensions of Glove Embeddings, the best model was with 300 dimensions of embeddings applied with CatBoost. I have also applied some tunings. Since there were not all the words of our text in the Glove embeddings I have both applied by just passing those words and randomly generating the embeddings vector for those words and then I have trained the model with both taking the mean and sum of the embeddings vectors. Model with nean of the embeddings was better. I have also fine tunned the scale of normal random number generation. At the end passing the words that are not existed in embeddings were returning better result.  
      </p>
      <p>
        You can check the project in details and the code 
        <a href="https://github.com/MertYILDIZ19/Text-Classification" target="_blank">
          here</a>.
      </p>
    </div>

    <div class="project">
      <h3>Image Classification with Shannon Information(Image Pixels as TF-IDF)</h3>
      <p>
        Recognition of images is a simple task for humans as it is easy to distinguish between different features. Somehow human brains are trained unconsciously with different or similar types of images that have helped human to distinguish between features (images) easily. However, machines need a lot of training for feature extraction which becomes a challenge due to high computation cost, memory requirement, and processing power. Nowadays, many new applications of image classification has been tried to decrease the memory requirement, computation cost and increase the accuracy of the classification of images. In this project a new approach on image classification has been applied from scratch. The main purpose is to try to increase the classification accuracy with a method that has never been applied, i.e. leveraging the usage of pixelâ€™s values Shannon informations (SI) in two different ways. Besides applying these approaches with a simple Convolutional Neural Network (CNN), in case of over fitting regular dropout and Monte Carlo(MC) dropout has been applied. In the end, a comparison between all the implemented models results has been performed.  
      </p>
      <p>
        You can check the project in details and the code 
        <a href="https://github.com/MertYILDIZ19/Image-Classification-with-Shannon-Information-Image-Pixels-as-TF-IDF-" target="_blank">
          here</a>.
      </p>
    </div>

    <div class="project">
      <h3>Building a Search Engine for GoodReads' Best Books Ever: Data Collection, Search Algorithms, and Score-based Ranking</h3>
      <p>
        This project focused on four questions related to building a search engine for the "best books ever" list on GoodReads. In the first question, data collection involved retrieving the URLs of books from the list's first 300 pages and downloading their corresponding HTML pages. The extracted information for each book included the title, series, author(s), ratings, reviews, plot, number of pages, publishing date, characters, setting, and URL.
      </p>

      <p>
        The second question involved creating two search engines. The first search engine utilized an inverted index, TF-IDF weighting, and cosine similarity to find the best matches for a given query. The second search engine provided a solution using built-in functions. In the third question, a new score was defined based on user-specified criteria and the cosine similarity between the book's plot and the query. The top 10 books with the highest new score were returned.
      </p>

      <p>
        The project also addressed an algorithmic question where the task was to find the longest subsequence of characters in alphabetical order from a given string of capital letters. Both recursive and dynamic programming algorithms were implemented, with the dynamic programming solution having a time complexity of O(nm).
      </p>


      <p>
        You can check the project in details and the code 
        <a href="https://github.com/MertYILDIZ19/GoodReads_Search_Engine" target="_blank">
          here</a>.
      </p>
    </div>
    
  </section>


  <footer>
    <div class="contact-info">
      <h2>Contact</h2>
      <p>Email: mrtyldz.1909@gmail.com</p>
      <p>Phone: +39 349 502 6016</p>

      <a href="https://www.linkedin.com/in/mertyldz/" target="_blank">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
          <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
        </svg>
      </a>
      <a href="https://github.com/MertYILDIZ19" target="_blank">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
          <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-4.466 19.59c-.405.078-.534-.171-.534-.384v-2.195c0-.747-.262-1.233-.55-1.481 1.782-.198 3.654-.875 3.654-3.947 0-.874-.312-1.588-.823-2.147.082-.202.356-1.016-.079-2.117 0 0-.671-.215-2.198.82-.64-.18-1.324-.267-2.004-.271-.68.003-1.364.091-2.003.269-1.528-1.035-2.2-.82-2.2-.82-.434 1.102-.16 1.915-.077 2.118-.512.56-.824 1.273-.824 2.147 0 3.064 1.867 3.751 3.645 3.954-.229.2-.436.552-.508 1.07-.457.204-1.614.557-2.328-.666 0 0-.423-.768-1.227-.825 0 0-.78-.01-.055.487 0 0 .525.246.889 1.17 0 0 .463 1.428 2.688.944v1.489c0 .211-.129.459-.528.385-3.18-1.057-5.472-4.056-5.472-7.59 0-4.419 3.582-8 8-8s8 3.581 8 8c0 3.533-2.289 6.531-5.466 7.59z"/>
        </svg>
      </a>
    </div>
  </footer>
  
</body>
</html>
